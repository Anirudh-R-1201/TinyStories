transformer.wte.weight torch.Size([50257, 768])
transformer.wpe.weight torch.Size([2048, 768])
transformer.h.0.ln_1.weight torch.Size([768])
transformer.h.0.ln_1.bias torch.Size([768])
transformer.h.0.attn.attention.k_proj.weight torch.Size([768, 768])
transformer.h.0.attn.attention.v_proj.weight torch.Size([768, 768])
transformer.h.0.attn.attention.q_proj.weight torch.Size([768, 768])
transformer.h.0.attn.attention.out_proj.weight torch.Size([768, 768])
transformer.h.0.attn.attention.out_proj.bias torch.Size([768])
transformer.h.0.ln_2.weight torch.Size([768])
transformer.h.0.ln_2.bias torch.Size([768])
transformer.h.0.mlp.c_fc.weight torch.Size([3072, 768])
transformer.h.0.mlp.c_fc.bias torch.Size([3072])
transformer.h.0.mlp.c_proj.weight torch.Size([768, 3072])
transformer.h.0.mlp.c_proj.bias torch.Size([768])
transformer.h.1.ln_1.weight torch.Size([768])
transformer.h.1.ln_1.bias torch.Size([768])
transformer.h.1.attn.attention.k_proj.weight torch.Size([768, 768])
transformer.h.1.attn.attention.v_proj.weight torch.Size([768, 768])
transformer.h.1.attn.attention.q_proj.weight torch.Size([768, 768])
transformer.h.1.attn.attention.out_proj.weight torch.Size([768, 768])
transformer.h.1.attn.attention.out_proj.bias torch.Size([768])
transformer.h.1.ln_2.weight torch.Size([768])
transformer.h.1.ln_2.bias torch.Size([768])
transformer.h.1.mlp.c_fc.weight torch.Size([3072, 768])
transformer.h.1.mlp.c_fc.bias torch.Size([3072])
transformer.h.1.mlp.c_proj.weight torch.Size([768, 3072])
transformer.h.1.mlp.c_proj.bias torch.Size([768])
transformer.h.2.ln_1.weight torch.Size([768])
transformer.h.2.ln_1.bias torch.Size([768])
transformer.h.2.attn.attention.k_proj.weight torch.Size([768, 768])
transformer.h.2.attn.attention.v_proj.weight torch.Size([768, 768])
transformer.h.2.attn.attention.q_proj.weight torch.Size([768, 768])
transformer.h.2.attn.attention.out_proj.weight torch.Size([768, 768])
transformer.h.2.attn.attention.out_proj.bias torch.Size([768])
transformer.h.2.ln_2.weight torch.Size([768])
transformer.h.2.ln_2.bias torch.Size([768])
transformer.h.2.mlp.c_fc.weight torch.Size([3072, 768])
transformer.h.2.mlp.c_fc.bias torch.Size([3072])
transformer.h.2.mlp.c_proj.weight torch.Size([768, 3072])
transformer.h.2.mlp.c_proj.bias torch.Size([768])
transformer.h.3.ln_1.weight torch.Size([768])
transformer.h.3.ln_1.bias torch.Size([768])
transformer.h.3.attn.attention.k_proj.weight torch.Size([768, 768])
transformer.h.3.attn.attention.v_proj.weight torch.Size([768, 768])
transformer.h.3.attn.attention.q_proj.weight torch.Size([768, 768])
transformer.h.3.attn.attention.out_proj.weight torch.Size([768, 768])
transformer.h.3.attn.attention.out_proj.bias torch.Size([768])
transformer.h.3.ln_2.weight torch.Size([768])
transformer.h.3.ln_2.bias torch.Size([768])
transformer.h.3.mlp.c_fc.weight torch.Size([3072, 768])
transformer.h.3.mlp.c_fc.bias torch.Size([3072])
transformer.h.3.mlp.c_proj.weight torch.Size([768, 3072])
transformer.h.3.mlp.c_proj.bias torch.Size([768])
transformer.ln_f.weight torch.Size([768])
transformer.ln_f.bias torch.Size([768])
lm_head.weight torch.Size([50257, 768])